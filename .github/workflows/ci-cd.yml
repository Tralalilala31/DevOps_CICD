on:
  push:
    branches: ['*']
  pull_request:
    branches: ['*']
  schedule:
    - cron: '0 22 * * *'

name: CI/CD Pipeline

env:
  PROJECT_NAME: cicd_project

jobs:
  build_frontend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup environment variables for frontend
        run: |
          cat > front-end/.env << EOF
          VITE_API_URL=${{ secrets.FRONTEND_API_URL }}
          VITE_APP_NAME=${{ env.PROJECT_NAME }}
          VITE_APP_VERSION=${{ github.ref_name }}
          VITE_ENVIRONMENT=ci
          EOF

      - name: Install dependencies & build frontend
        run: |
          cd front-end
          npm ci
          npm run build

  build_test_backend:
    runs-on: ubuntu-latest
    services:
      mysql:
        image: mysql:8.0.32
        env:
          MYSQL_DATABASE: ${{ env.PROJECT_NAME }}
          MYSQL_USER: ${{ secrets.DATABASE_ADMIN_USER }}
          MYSQL_PASSWORD: ${{ secrets.DATABASE_ADMIN_PASSWORD }}
          MYSQL_ROOT_PASSWORD: ${{ secrets.DATABASE_ROOT_PASSWORD }}
        ports: ['3306:3306']
        options: >-
          --health-cmd="mysqladmin ping -h localhost"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10

    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      - name: Générer le fichier .env pour le backend
        run: |
          cd back-end
          echo "PROJECT_NAME=${{ env.PROJECT_NAME }}" > .env
          echo "DATABASE_ADMIN_USER=${{ secrets.DATABASE_ADMIN_USER }}" >> .env
          echo "DATABASE_ADMIN_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}" >> .env
          echo "DATABASE_ROOT_PASSWORD=${{ secrets.DATABASE_ROOT_PASSWORD }}" >> .env
          echo "DB_HOST=127.0.0.1" >> .env
          echo "DB_PORT=3306" >> .env
          echo "DB_USER=${{ secrets.DATABASE_ADMIN_USER }}" >> .env
          echo "DB_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}" >> .env
          echo "DB_NAME=${{ env.PROJECT_NAME }}" >> .env
          echo "NODE_ENV=test" >> .env
          echo "FRONTEND_URL=http://localhost:4200" >> .env
          
          echo "=== Contenu du fichier .env généré (sans secrets) ==="
          cat .env | grep -v PASSWORD | grep -v SECRET

      - name: Install backend dependencies
        run: |
          cd back-end
          npm ci

      - name: Run unit and integration tests
        run: |
          cd back-end
          npm run test:unit
          npm run test:integration

  perf_tests:
    needs: build_test_backend
    runs-on: ubuntu-latest
    services:
      mysql:
        image: mysql:8.0.32
        env:
          MYSQL_DATABASE: ${{ env.PROJECT_NAME }}
          MYSQL_USER: ${{ secrets.DATABASE_ADMIN_USER }}
          MYSQL_PASSWORD: ${{ secrets.DATABASE_ADMIN_PASSWORD }}
          MYSQL_ROOT_PASSWORD: ${{ secrets.DATABASE_ROOT_PASSWORD }}
        ports: ['3306:3306']
        options: >-
          --health-cmd="mysqladmin ping -h localhost"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10

    steps:
      - uses: actions/checkout@v3

      - name: Generate complete .env for performance tests
        run: |
          cd back-end
          cat > .env << EOF
          PROJECT_NAME=${{ env.PROJECT_NAME }}
          
          DATABASE_ADMIN_USER=${{ secrets.DATABASE_ADMIN_USER }}
          DATABASE_ADMIN_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}
          DATABASE_ROOT_PASSWORD=${{ secrets.DATABASE_ROOT_PASSWORD }}
          DB_HOST=127.0.0.1
          DB_PORT=3306
          DB_USER=${{ secrets.DATABASE_ADMIN_USER }}
          DB_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}
          DB_NAME=${{ env.PROJECT_NAME }}
          
          NODE_ENV=performance
          
          PERF_TEST_DURATION=60
          PERF_TEST_CONCURRENT_USERS=100
          EOF

      - name: Install and run performance tests
        run: |
          cd back-end/tests/perf
          npm ci
          node perf-test.js

  e2e_tests:
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v3

      - name: Configure docker-compose environment
        run: |
          sudo apt-get update && sudo apt-get install -y gettext-base
          
          export PROJECT_NAME=${{ env.PROJECT_NAME }}
          export DATABASE_ADMIN_USER=${{ secrets.DATABASE_ADMIN_USER }}
          export DATABASE_ADMIN_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}
          export DATABASE_ROOT_PASSWORD=${{ secrets.DATABASE_ROOT_PASSWORD }}
          
          envsubst < docker-compose.template.yml > docker-compose.yml

      - name: Setup E2E environment
        run: |
          docker-compose up -d
          sleep 10

      - name: Run E2E tests
        run: |
          cd e2e-tests
          npm ci
          npm run test:e2e

  deploy_staging:
    needs: [build_frontend, build_test_backend]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment:
      name: staging
      url: http://212.83.130.245:3000

    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      - name: Install sshpass for SSH authentication
        run: |
          sudo apt-get update
          sudo apt-get install -y sshpass rsync

      - name: Configure staging environment
        run: |
          cat > .env.staging << EOF
          PROJECT_NAME=${{ env.PROJECT_NAME }}
          NODE_ENV=staging
          DATABASE_ADMIN_USER=${{ secrets.DATABASE_ADMIN_USER }}
          DATABASE_ADMIN_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}
          DATABASE_ROOT_PASSWORD=${{ secrets.DATABASE_ROOT_PASSWORD }}
          DB_HOST=mysql
          DB_PORT=3306
          DB_NAME=${{ env.PROJECT_NAME }}_staging
          APP_URL=http://212.83.130.245:3000
          API_URL=http://212.83.130.245:3001
          PORT=3001
          FRONTEND_PORT=3000
          EOF

      - name: Build application for staging
        run: |
          cd front-end
          npm ci
          npm run build
          cd ..
          
          cd back-end
          npm ci
          cd ..

      - name: Create deployment package
        run: |
          mkdir -p deploy/staging
          
          # Copier la structure complète des applications
          cp -r back-end deploy/staging/
          cp -r front-end deploy/staging/
          
          # Créer les Dockerfiles s'ils n'existent pas
          if [ ! -f "back-end/Dockerfile" ]; then
            echo "Creating backend Dockerfile..."
            cat > deploy/staging/back-end/Dockerfile << 'DOCKERFILE_EOF'
          FROM node:20-alpine
          
          WORKDIR /app
          
          COPY package*.json ./
          RUN npm ci --only=production
          
          COPY . .
          
          ENV NODE_ENV=staging
          ENV PORT=3001
          
          EXPOSE 3001
          
          RUN addgroup -g 1001 -S nodejs && adduser -S nextjs -u 1001
          RUN chown -R nextjs:nodejs /app
          USER nextjs
          
          CMD ["npm", "start"]
          DOCKERFILE_EOF
          else
            cp back-end/Dockerfile deploy/staging/back-end/
          fi
          
          if [ ! -f "front-end/Dockerfile" ]; then
            echo "Creating frontend Dockerfile..."
            cat > deploy/staging/front-end/Dockerfile << 'DOCKERFILE_EOF'
          FROM node:20-alpine AS builder
          
          WORKDIR /app
          COPY package*.json ./
          RUN npm ci
          COPY . .
          RUN npm run build
          
          FROM nginx:alpine
          COPY --from=builder /app/dist /usr/share/nginx/html
          
          RUN echo 'server {' > /etc/nginx/conf.d/default.conf && \
              echo '    listen 80;' >> /etc/nginx/conf.d/default.conf && \
              echo '    server_name localhost;' >> /etc/nginx/conf.d/default.conf && \
              echo '    root /usr/share/nginx/html;' >> /etc/nginx/conf.d/default.conf && \
              echo '    index index.html;' >> /etc/nginx/conf.d/default.conf && \
              echo '    location / {' >> /etc/nginx/conf.d/default.conf && \
              echo '        try_files $uri $uri/ /index.html;' >> /etc/nginx/conf.d/default.conf && \
              echo '    }' >> /etc/nginx/conf.d/default.conf && \
              echo '}' >> /etc/nginx/conf.d/default.conf
          
          EXPOSE 80
          CMD ["nginx", "-g", "daemon off;"]
          DOCKERFILE_EOF
          else
            cp front-end/Dockerfile deploy/staging/front-end/
          fi
          
          # Copier les fichiers de configuration
          cp .env.staging deploy/staging/.env
          
          # Créer le docker-compose.yml avec les variables substituées
          cat > deploy/staging/docker-compose.yml << EOF
          name: ${{ env.PROJECT_NAME }}-staging
          
          services:
            backend:
              build:
                context: ./back-end
                dockerfile: Dockerfile
              ports:
                - "3001:3001"
              environment:
                - NODE_ENV=staging
                - PROJECT_NAME=${{ env.PROJECT_NAME }}
                - DB_HOST=mysql
                - DB_PORT=3306
                - DB_NAME=${{ env.PROJECT_NAME }}_staging
                - DB_USER=admin
                - DB_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}
                - DATABASE_ROOT_PASSWORD=${{ secrets.DATABASE_ROOT_PASSWORD }}
              depends_on:
                mysql:
                  condition: service_healthy
          
            frontend:
              build:
                context: ./front-end
                dockerfile: Dockerfile
              ports:
                - "3000:80"
              depends_on:
                - backend
          
            mysql:
              image: mysql:8.0
              environment:
                MYSQL_DATABASE: ${{ env.PROJECT_NAME }}_staging
                MYSQL_USER: admin
                MYSQL_PASSWORD: ${{ secrets.DATABASE_ADMIN_PASSWORD }}
                MYSQL_ROOT_PASSWORD: ${{ secrets.DATABASE_ROOT_PASSWORD }}
              volumes:
                - mysql-data:/var/lib/mysql
              healthcheck:
                test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
                interval: 10s
                timeout: 5s
                retries: 5
          
          volumes:
            mysql-data:
              name: "${{ env.PROJECT_NAME }}-staging-db"
          EOF
          
          tar -czf staging-deployment.tar.gz -C deploy/staging .

      - name: Upload deployment package to server
        run: |
          echo "📦 Transfert du package de déploiement vers staging"
          
          sshpass -p '${{ secrets.STAGING_SSH_PASSWORD }}' rsync -avz --delete \
            -e "ssh -o StrictHostKeyChecking=no" \
            staging-deployment.tar.gz ${{ secrets.STAGING_SSH_USER }}@${{ secrets.STAGING_SSH_HOST }}:/home/cicd/

      - name: Deploy to staging server
        run: |
          echo "🟢 Déploiement vers staging sur ${{ secrets.STAGING_SSH_HOST }}"
          
          sshpass -p '${{ secrets.STAGING_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
            ${{ secrets.STAGING_SSH_USER }}@${{ secrets.STAGING_SSH_HOST }} << 'EOF'
            set -e
          
            # Configuration des variables d'environnement
            export PROJECT_NAME=${{ env.PROJECT_NAME }}
            export DATABASE_ADMIN_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}
            export DATABASE_ROOT_PASSWORD=${{ secrets.DATABASE_ROOT_PASSWORD }}
          
            mkdir -p ~/.local/bin
            export PATH=$HOME/.local/bin:$PATH
          
            # Installation de docker-compose si nécessaire
            if ! command -v docker-compose &> /dev/null; then
              echo "🧩 Installation locale de docker-compose..."
              curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o ~/.local/bin/docker-compose
              chmod +x ~/.local/bin/docker-compose
            fi
          
            # Création du répertoire de staging et nettoyage
            mkdir -p /home/cicd/staging
            cd /home/cicd
          
            # Suppression des anciens fichiers de configuration
            rm -f /home/cicd/staging/compose.yml
            rm -f /home/cicd/staging/docker-compose.override.yml
          
            # Extraction du package
            tar -xzf staging-deployment.tar.gz -C staging/
            cd staging
          
            # Arrêt des services existants
            ~/.local/bin/docker-compose down || true
          
            # Nettoyage des images obsolètes
            docker image prune -f || true
          
            # Démarrage des nouveaux services
            ~/.local/bin/docker-compose up --build -d
          
            echo "⏳ Attente du démarrage des services..."
            sleep 15
          
            # Vérification du statut
            ~/.local/bin/docker-compose ps
          
            echo "✅ Déploiement staging terminé"
          EOF

      - name: Verify staging deployment
        run: |
          echo "🔍 Vérification du déploiement staging"
          sleep 30
          
          # Test de l'API
          if curl -f --max-time 10 http://212.83.130.245:3001/health; then
            echo "✅ API health check passed"
          else
            echo "⚠️ API health check failed"
          fi
          
          # Test du frontend
          if curl -f --max-time 10 http://212.83.130.245:3000; then
            echo "✅ Frontend check passed"
          else
            echo "⚠️ Frontend check failed"
          fi
          
          echo "✅ Déploiement staging vérifié"

  deploy_production:
    needs: deploy_staging
    if: startsWith(github.ref, 'refs/tags/v')
    runs-on: ubuntu-latest
    environment:
      name: production
      url: http://212.83.130.245:4000

    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      - name: Install sshpass for SSH authentication
        run: |
          sudo apt-get update
          sudo apt-get install -y sshpass rsync

      - name: Configure production environment securely
        run: |
          umask 077
          
          cat > .env.production << EOF
          PROJECT_NAME=${{ env.PROJECT_NAME }}
          NODE_ENV=production
          
          DATABASE_ADMIN_USER=${{ secrets.DATABASE_ADMIN_USER }}
          DATABASE_ADMIN_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}
          DATABASE_ROOT_PASSWORD=${{ secrets.DATABASE_ROOT_PASSWORD }}
          DB_HOST=mysql
          DB_PORT=3306
          DB_NAME=${{ env.PROJECT_NAME }}_prod
          
          APP_URL=http://212.83.130.245:4000
          API_URL=http://212.83.130.245:4001
          PORT=4001
          FRONTEND_PORT=4000
          
          APP_VERSION=${{ github.ref_name }}
          BUILD_NUMBER=${{ github.run_number }}
          COMMIT_SHA=${{ github.sha }}
          
          LOG_LEVEL=info
          MAX_REQUEST_SIZE=10mb
          RATE_LIMIT_WINDOW=900000
          RATE_LIMIT_MAX=100
          EOF

      - name: Build application for production
        run: |
          cd front-end
          npm ci
          NODE_ENV=production npm run build
          cd ..
          
          cd back-end
          npm ci --production
          cd ..

      - name: Create production deployment package
        run: |
          mkdir -p deploy/production
          
          # Copier la structure complète des applications
          cp -r back-end deploy/production/
          cp -r front-end deploy/production/
          
          # Créer les Dockerfiles s'ils n'existent pas
          if [ ! -f "back-end/Dockerfile" ]; then
            echo "Creating backend Dockerfile for production..."
            cat > deploy/production/back-end/Dockerfile << 'DOCKERFILE_EOF'
          FROM node:20-alpine
          
          WORKDIR /app
          
          COPY package*.json ./
          RUN npm ci --only=production
          
          COPY . .
          
          ENV NODE_ENV=production
          ENV PORT=4001
          
          EXPOSE 4001
          
          RUN addgroup -g 1001 -S nodejs && adduser -S nextjs -u 1001
          RUN chown -R nextjs:nodejs /app
          USER nextjs
          
          CMD ["npm", "start"]
          DOCKERFILE_EOF
          else
            cp back-end/Dockerfile deploy/production/back-end/
          fi
          
          if [ ! -f "front-end/Dockerfile" ]; then
            echo "Creating frontend Dockerfile for production..."
            cat > deploy/production/front-end/Dockerfile << 'DOCKERFILE_EOF'
          FROM node:20-alpine AS builder
          
          WORKDIR /app
          COPY package*.json ./
          RUN npm ci
          COPY . .
          RUN npm run build
          
          FROM nginx:alpine
          COPY --from=builder /app/dist /usr/share/nginx/html
          
          RUN echo 'server {' > /etc/nginx/conf.d/default.conf && \
              echo '    listen 80;' >> /etc/nginx/conf.d/default.conf && \
              echo '    server_name localhost;' >> /etc/nginx/conf.d/default.conf && \
              echo '    root /usr/share/nginx/html;' >> /etc/nginx/conf.d/default.conf && \
              echo '    index index.html;' >> /etc/nginx/conf.d/default.conf && \
              echo '    location / {' >> /etc/nginx/conf.d/default.conf && \
              echo '        try_files $uri $uri/ /index.html;' >> /etc/nginx/conf.d/default.conf && \
              echo '    }' >> /etc/nginx/conf.d/default.conf && \
              echo '}' >> /etc/nginx/conf.d/default.conf
          
          EXPOSE 80
          CMD ["nginx", "-g", "daemon off;"]
          DOCKERFILE_EOF
          else
            cp front-end/Dockerfile deploy/production/front-end/
          fi
          
          # Copier les fichiers de configuration
          cp .env.production deploy/production/.env
          
          # Créer le docker-compose.yml pour la production
          cat > deploy/production/docker-compose.yml << EOF
          name: ${{ env.PROJECT_NAME }}-production
          
          services:
            backend:
              build:
                context: ./back-end
                dockerfile: Dockerfile
              ports:
                - "4001:4001"
              environment:
                - NODE_ENV=production
                - PROJECT_NAME=${{ env.PROJECT_NAME }}
                - DB_HOST=mysql
                - DB_PORT=3306
                - DB_NAME=${{ env.PROJECT_NAME }}_prod
                - DB_USER=admin
                - DB_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}
                - DATABASE_ROOT_PASSWORD=${{ secrets.DATABASE_ROOT_PASSWORD }}
              depends_on:
                mysql:
                  condition: service_healthy
              restart: unless-stopped
          
            frontend:
              build:
                context: ./front-end
                dockerfile: Dockerfile
              ports:
                - "4000:80"
              depends_on:
                - backend
              restart: unless-stopped
          
            mysql:
              image: mysql:8.0
              environment:
                MYSQL_DATABASE: ${{ env.PROJECT_NAME }}_prod
                MYSQL_USER: admin
                MYSQL_PASSWORD: ${{ secrets.DATABASE_ADMIN_PASSWORD }}
                MYSQL_ROOT_PASSWORD: ${{ secrets.DATABASE_ROOT_PASSWORD }}
              volumes:
                - mysql-data:/var/lib/mysql
              healthcheck:
                test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
                interval: 10s
                timeout: 5s
                retries: 5
              restart: unless-stopped
          
          volumes:
            mysql-data:
              name: "${{ env.PROJECT_NAME }}-production-db"
          EOF
          
          # Copier les scripts de sauvegarde si ils existent
          mkdir -p deploy/production/scripts
          cp scripts/backup-db.sh deploy/production/scripts/ 2>/dev/null || echo "Warning: backup-db.sh not found"
          cp scripts/health-check.sh deploy/production/scripts/ 2>/dev/null || echo "Warning: health-check.sh not found"
          
          tar -czf production-deployment.tar.gz -C deploy/production .

      - name: Backup current production (if exists)
        run: |
          echo "💾 Sauvegarde de la production actuelle"
          
          sshpass -p '${{ secrets.PROD_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
            ${{ secrets.PROD_SSH_USER }}@${{ secrets.PROD_SSH_HOST }} << EOF
            # Créer le dossier de backup avec timestamp
            BACKUP_DIR="/home/cicd/backups/\$(date +%Y%m%d_%H%M%S)"
            mkdir -p \$BACKUP_DIR
          
            if [ -d "/home/cicd/production" ]; then
              cp -r /home/cicd/production \$BACKUP_DIR/
              echo "✅ Backup créé dans \$BACKUP_DIR"
            fi
          
            # Backup de la base de données si possible
            if command -v docker &> /dev/null && docker ps | grep mysql; then
              docker exec \$(docker ps --format "table {{.Names}}" | grep mysql | head -1) mysqldump -u root -p${{ secrets.DATABASE_ROOT_PASSWORD }} ${{ env.PROJECT_NAME }}_prod > \$BACKUP_DIR/database.sql 2>/dev/null || echo "Warning: Database backup failed"
            fi
          EOF

      - name: Upload production package to server
        run: |
          echo "📦 Transfert du package de production"
          
          sshpass -p '${{ secrets.PROD_SSH_PASSWORD }}' rsync -avz --delete \
            -e "ssh -o StrictHostKeyChecking=no" \
            production-deployment.tar.gz ${{ secrets.PROD_SSH_USER }}@${{ secrets.PROD_SSH_HOST }}:/home/cicd/

      - name: Deploy to production server
        run: |
          echo "🚀 Déploiement vers production sur ${{ secrets.PROD_SSH_HOST }}"
          
          sshpass -p '${{ secrets.PROD_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
            ${{ secrets.PROD_SSH_USER }}@${{ secrets.PROD_SSH_HOST }} << 'EOF'
            set -e
          
            # Configuration des variables d'environnement
            export PROJECT_NAME=${{ env.PROJECT_NAME }}
            export DATABASE_ADMIN_PASSWORD=${{ secrets.DATABASE_ADMIN_PASSWORD }}
            export DATABASE_ROOT_PASSWORD=${{ secrets.DATABASE_ROOT_PASSWORD }}
          
            mkdir -p /home/cicd/production
            cd /home/cicd
          
            # Suppression des anciens fichiers de configuration conflictuels
            rm -f /home/cicd/production/compose.yml
            rm -f /home/cicd/production/docker-compose.override.yml
          
            # Extraction du package
            tar -xzf production-deployment.tar.gz -C production/
            cd production
          
            echo "🔄 Mise à jour en cours..."
          
            # Build des images
            docker-compose build
          
            # Démarrage des services
            docker-compose up -d --force-recreate --remove-orphans
          
            echo "⏳ Attente du démarrage des services..."
            sleep 30
          
            # Vérification du statut
            docker-compose ps
            echo "✅ Déploiement terminé"
          EOF

      - name: Run production health checks
        run: |
          echo "🏥 Vérifications de santé production"
          sleep 60 
          
          echo "Test API health endpoint..."
          if curl -f --max-time 10 http://212.83.130.245:4001/health; then
            echo "✅ API health check passed"
          else
            echo "❌ API health check failed"
            exit 1
          fi
          
          echo "Test frontend availability..."
          if curl -f --max-time 10 http://212.83.130.245:4000; then
            echo "✅ Frontend check passed"
          else
            echo "❌ Frontend check failed"
            exit 1
          fi
          
          echo "Test de performance basique..."
          response_time=$(curl -o /dev/null -s -w "%{time_total}" http://212.83.130.245:4001/health)
          echo "Temps de réponse API: ${response_time}s"
          
          # Vérification du temps de réponse (compatible avec différents systèmes)
          if command -v bc &> /dev/null; then
            if (( $(echo "$response_time > 2.0" | bc -l) )); then
              echo "⚠️ API response time is high: ${response_time}s"
            fi
          else
            echo "⚠️ bc not available, skipping response time check"
          fi
          
          echo "✅ Déploiement production vérifié et fonctionnel"

      - name: Notify production deployment success
        run: |
          echo "🎉 Production deployée avec succès!"
          echo "Version: ${{ github.ref_name }}"
          echo "URL: http://212.83.130.245:4000"

  notify_webhook_success:
    if: success()
    needs: [ deploy_staging, deploy_production ]
    runs-on: ubuntu-latest
    steps:
      - name: Notify success
        run: |
          curl -X POST ${{ secrets.WEBHOOK_URL }} \
            -H "Content-Type: application/json" \
            -d '{
              "status": "success", 
              "message": "✅ Build & deploy completed",
              "project": "${{ env.PROJECT_NAME }}",
              "version": "${{ github.ref_name }}",
              "environment": "production"
            }' || echo "Webhook notification failed"

  notify_webhook_failure:
    if: failure()
    runs-on: ubuntu-latest
    steps:
      - name: Notify failure
        run: |
          curl -X POST ${{ secrets.WEBHOOK_URL }} \
            -H "Content-Type: application/json" \
            -d '{
              "status": "failure", 
              "message": "❌ Échec du pipeline CI/CD",
              "project": "${{ env.PROJECT_NAME }}",
              "branch": "${{ github.ref_name }}"
            }' || echo "Webhook notification failed"