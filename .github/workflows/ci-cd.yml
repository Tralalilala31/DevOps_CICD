on:
  push:
    branches: ['**']
  pull_request:
    branches: ['**']
  schedule:
    - cron: '0 22 * * *'

name: CI/CD Pipeline

env:
  PROJECT_NAME: cicd_project

jobs:
  build_frontend:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Builder le frontend via Docker Compose
        run: docker compose build frontend

  build_test_backend:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Lancer l'environnement en fond
        run: docker compose up -d --build

      - name: Run unit and integration tests
        run: |
          docker compose up -d --build
          docker compose exec backend npm run test:unit

      - name: Nettoyage
        run: docker compose down --volumes

  perf_tests:
    needs: build_test_backend
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Start containers for perf tests
        run: docker compose up -d --build

      - name: Run performance tests inside backend
        run: docker compose exec backend node tests/perf/perf-test.js

      - name: Nettoyage
        if: always()
        run: docker compose down --volumes

  e2e_tests:
    # if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v3

      - name: Lancer les tests E2E
        run: |
          docker compose -f compose.yml up -d --build
          npm ci
          npm run e2e

      - name: Nettoyage
        if: always()
        run: docker compose -f compose.yml down --volumes

  deploy_staging:
    needs: [build_frontend, build_test_backend]
    runs-on: ubuntu-latest
    environment:
      name: staging
      url: http://212.83.130.245:3000

    steps:
      - uses: actions/checkout@v3

      - name: Install sshpass
        run: |
          sudo apt-get update
          sudo apt-get install -y sshpass

      - name: G√©n√©rer .env.staging
        run: |
          mkdir -p back-end
          sed -e "s|\${PROJECT_NAME}|${{ env.PROJECT_NAME }}|g" \
              -e "s|\${DATABASE_ADMIN_USER}|${{ secrets.DATABASE_ADMIN_USER }}|g" \
              -e "s|\${DATABASE_ADMIN_PASSWORD}|${{ secrets.DATABASE_ADMIN_PASSWORD }}|g" \
              -e "s|\${DATABASE_ROOT_PASSWORD}|${{ secrets.DATABASE_ROOT_PASSWORD }}|g" \
              -e "s|\${NODE_ENV}|staging|g" \
              -e "s|\${APP_URL}|http://212.83.130.245|g" \
              -e "s|\${API_URL}|http://212.83.130.245:3000|g" \
              -e "s|\${PORT}|3000|g" \
              -e "s|\${FRONTEND_PORT}|80|g" \
              -e "s|\${PHPMYADMIN_PORT}|8080|g" \
              -e "s|\${MYSQL_VERSION}|8.0.32|g" \
              -e "s|DB_HOST=.*|DB_HOST=mysql|g" \
              -e "s|DB_PORT=.*|DB_PORT=3306|g" \
              -e "s|DB_USER=.*|DB_USER=${{ secrets.DATABASE_ADMIN_USER }}|g" \
              -e "s|DB_PASSWORD=.*|DB_PASSWORD=${{ env.DATABASE_ADMIN_PASSWORD }}|g" \
              .env.template > back-end/.env.staging

      - name: Cr√©er le paquet de d√©ploiement
        run: |
          mkdir -p deploy/staging
          cp -r front-end back-end compose.yml deploy/staging/
          cp back-end/.env.staging deploy/staging/back-end/.env.staging
          cp .env* compose*.yml deploy/staging/
          tar -czf staging-deployment.tar.gz -C deploy/staging .

      - name: V√©rifier le contenu avant tar
        run: |
          ls -R deploy/staging/back-end
          ls -R deploy/staging/front-end

      - name: Nettoyer les ports en conflit sur le serveur staging
        run: |
          sshpass -p '${{ secrets.STAGING_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
            ${{ secrets.STAGING_SSH_USER }}@${{ secrets.STAGING_SSH_HOST }} << 'EOF'
          
            echo "üßπ Nettoyage des ports potentiellement en conflit..."
          
            # Arr√™ter tous les conteneurs Docker qui pourraient utiliser les ports
            docker stop $(docker ps -q) 2>/dev/null || true
          
            # Lib√©rer explicitement les ports utilis√©s par le staging
            sudo fuser -k 300/tcp 2>/dev/null || true
            sudo fuser -k 80/tcp 2>/dev/null || true
            sudo fuser -k 8080/tcp 2>/dev/null || true
          
            # V√©rifier que les ports sont libres
            if ss -tuln | grep -q ":3000 "; then
              echo "‚ö†Ô∏è Port 3000 encore utilis√©"
              ss -tuln | grep ":3000 "
            fi
          
            if ss -tuln | grep -q ":80 "; then
              echo "‚ö†Ô∏è Port 80 encore utilis√©"
              ss -tuln | grep ":80 "
            fi
          
            echo "‚úÖ Nettoyage termin√©"
          EOF

      - name: D√©ployer sur le serveur staging
        run: |
          sshpass -p '${{ secrets.STAGING_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
            ${{ secrets.STAGING_SSH_USER }}@${{ secrets.STAGING_SSH_HOST }} << 'EOF'
          
            set -e
            mkdir -p /home/cicd/staging
            cd /home/cicd
          
            if ! command -v docker &> /dev/null; then
              echo "‚ùå Docker n'est pas install√©"
              exit 1
            fi
          
            if ! docker compose version &> /dev/null; then
              echo "üß© Installation de docker compose v2..."
              mkdir -p ~/.docker/cli-plugins
              curl -SL https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) \
                -o ~/.docker/cli-plugins/docker-compose
              chmod +x ~/.docker/cli-plugins/docker-compose
            fi
          
            rm -rf staging/*

      - name: Transf√©rer les fichiers
        run: |
          sshpass -p '${{ secrets.STAGING_SSH_PASSWORD }}' scp -o StrictHostKeyChecking=no \
            staging-deployment.tar.gz \
            ${{ secrets.STAGING_SSH_USER }}@${{ secrets.STAGING_SSH_HOST }}:/home/cicd/

      - name: D√©ployer les containers avec gestion des conflits de ports
        run: |
          sshpass -p '${{ secrets.STAGING_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
            ${{ secrets.STAGING_SSH_USER }}@${{ secrets.STAGING_SSH_HOST }} << 'EOF'
            cd /home/cicd
            tar -xzf staging-deployment.tar.gz -C staging/
            cd staging
          
            # Arr√™ter compl√®tement tous les conteneurs existants
            echo "üõë Arr√™t forc√© de tous les conteneurs Docker..."
            docker compose down --volumes --remove-orphans 2>/dev/null || true
            docker system prune -f --volumes 2>/dev/null || true
          
            # Attendre un peu pour que les ports se lib√®rent
            sleep 5
          
            # V√©rifier une derni√®re fois les ports
            echo "üîç V√©rification finale des ports..."
            for port in 3001 8080 8081; do
              if ss -tuln | grep -q ":${port} "; then
                echo "‚ùå Port ${port} encore occup√©, tentative de lib√©ration..."
                sudo fuser -k ${port}/tcp 2>/dev/null || true
                sleep 2
              fi
            done
          
            # Copier et sourcer le fichier d'environnement
            cp .env.staging .env
          
            echo "üöÄ D√©marrage des services avec les nouveaux ports..."
            # D√©marrer les services avec retry en cas d'√©chec
            max_retries=3
            retry_count=0
          
            while [ $retry_count -lt $max_retries ]; do
              if docker compose up -d --build; then
                echo "‚úÖ Services d√©marr√©s avec succ√®s"
                break
              else
                retry_count=$((retry_count + 1))
                echo "‚ö†Ô∏è √âchec tentative $retry_count/$max_retries, nouvelle tentative dans 10s..."
                docker compose down --volumes --remove-orphans 2>/dev/null || true
                sleep 10
              fi
            done
          
            if [ $retry_count -eq $max_retries ]; then
              echo "‚ùå √âchec du d√©marrage apr√®s $max_retries tentatives"
              exit 1
            fi
          
            echo "‚åõ Attente du d√©marrage des services..."
          
            # Attendre que tous les services soient healthy
            timeout=180
            elapsed=0
            while [ $elapsed -lt $timeout ]; do
              if docker compose ps --filter "status=running" | grep -q "healthy\|Up"; then
                healthy_count=$(docker compose ps --filter "status=running" | grep -c "healthy\|Up" || echo "0")
                total_services=$(docker compose ps | wc -l)
                echo "Services sains: $healthy_count"
                if [ "$healthy_count" -ge 3 ]; then
                  echo "‚úÖ Services d√©marr√©s avec succ√®s"
                  break
                fi
              fi
              echo "‚è≥ Attente des services... ($elapsed/$timeout s)"
              sleep 10
              elapsed=$((elapsed + 10))
            done
          
            if [ $elapsed -ge $timeout ]; then
              echo "‚ùå Timeout: Les services n'ont pas d√©marr√© √† temps"
              docker compose ps
              docker compose logs --tail=50
              exit 1
            fi
          
            echo "üìä √âtat final des conteneurs:"
            docker compose ps
          EOF

      - name: V√©rification du d√©ploiement avec les nouveaux ports
        run: |
          echo "üîç V√©rification du staging avec les nouveaux ports"
          
          # Fonction de retry
          retry_curl() {
            local url=$1
            local service_name=$2
            local max_attempts=12
            local wait_time=10
          
            for i in $(seq 1 $max_attempts); do
              echo "Tentative $i/$max_attempts pour $service_name..."
              if curl -f --connect-timeout 10 --max-time 30 "$url"; then
                echo "‚úÖ $service_name disponible"
                return 0
              fi
              echo "‚è≥ $service_name non disponible, attente ${wait_time}s..."
              sleep $wait_time
            done
          
            echo "‚ùå $service_name indisponible apr√®s $max_attempts tentatives"
            return 1
          }
          
          # V√©rifier l'API sur le nouveau port
          if ! retry_curl "http://212.83.130.245:3000/health" "API (port 3000)"; then
            echo "üîç Diagnostic API..."
            sshpass -p '${{ secrets.STAGING_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
              ${{ secrets.STAGING_SSH_USER }}@${{ secrets.STAGING_SSH_HOST }} \
              "cd /home/cicd/staging && docker compose logs backend --tail=50"
            exit 1
          fi
          
          # V√©rifier le Frontend sur le nouveau port
          if ! retry_curl "http://212.83.130.245" "Frontend (port 80)"; then
            echo "üîç Diagnostic Frontend..."
            sshpass -p '${{ secrets.STAGING_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
              ${{ secrets.STAGING_SSH_USER }}@${{ secrets.STAGING_SSH_HOST }} \
              "cd /home/cicd/staging && docker compose logs frontend --tail=50"
            exit 1
          fi
          
          echo "‚úÖ Staging op√©rationnel sur les nouveaux ports"
          echo "üåê API: http://212.83.130.245:3000"
          echo "üåê Frontend: http://212.83.130.245"
          echo "üóÑÔ∏è PhpMyAdmin: http://212.83.130.245:8080"

  deploy_production:
    needs: deploy_staging
    if: startsWith(github.ref, 'refs/tags/v')
    runs-on: ubuntu-latest
    environment:
      name: production
      url: http://212.83.130.245:4000

    steps:
      - uses: actions/checkout@v3

      - name: Installer sshpass
        run: |
          sudo apt-get update
          sudo apt-get install -y sshpass

      - name: G√©n√©rer `.env.production`
        run: |
          sed -e "s|\${PROJECT_NAME}|${{ env.PROJECT_NAME }}|g" \
              -e "s|\${DATABASE_ADMIN_USER}|${{ secrets.DATABASE_ADMIN_USER }}|g" \
              -e "s|\${DATABASE_ADMIN_PASSWORD}|${{ secrets.DATABASE_ADMIN_PASSWORD }}|g" \
              -e "s|\${DATABASE_ROOT_PASSWORD}|${{ secrets.DATABASE_ROOT_PASSWORD }}|g" \
              -e "s|NODE_ENV=.*|NODE_ENV=production|g" \
              -e "s|DB_NAME=.*|DB_NAME=${{ env.PROJECT_NAME }}_prod|g" \
              -e "s|APP_URL=.*|APP_URL=http://212.83.130.245:4000|g" \
              -e "s|API_URL=.*|API_URL=http://212.83.130.245:4001|g" \
              -e "s|PORT=.*|PORT=4001|g" \
              -e "s|FRONTEND_PORT=.*|FRONTEND_PORT=4000|g" \
              -e "s|PHPMYADMIN_PORT=.*|PHPMYADMIN_PORT=4002|g" \
              -e "s|\${MYSQL_VERSION}|8.0|g" \
            .env.template > back-end/.env.production

      - name: Cr√©er le paquet de d√©ploiement
        run: |
          mkdir -p deploy/production
          cp -r front-end back-end back-end/.env.production compose.yml deploy/production/
          tar -czf production-deployment.tar.gz -C deploy/production .

      - name: Backup de la production existante
        run: |
          sshpass -p '${{ secrets.PROD_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
            ${{ secrets.PROD_SSH_USER }}@${{ secrets.PROD_SSH_HOST }} << 'EOF'
          
            set -e
          
            BACKUP_DIR="/home/cicd/backups/$(date +%Y%m%d_%H%M%S)"
            mkdir -p "$BACKUP_DIR"
          
            if [ -d "/home/cicd/production" ]; then
              cp -r /home/cicd/production "$BACKUP_DIR/"
              echo "‚úÖ Dossier copi√© : $BACKUP_DIR"
            fi
          
            # Sauvegarde DB si conteneur existant
            if docker ps --format '{{.Names}}' | grep -q cicd_project_mysql_prod; then
              docker exec cicd_project_mysql_prod \
                mysqladump -u root -p$DATABASE_ROOT_PASSWORD cicd_project_prod > "$BACKUP_DIR/db.sql" || true
              echo "üíæ Dump MySQL sauvegard√©."
            fi
          EOF

      - name: Pr√©parer le serveur distant
        run: |
          sshpass -p '${{ secrets.PROD_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
            ${{ secrets.PROD_SSH_USER }}@${{ secrets.PROD_SSH_HOST }} << 'EOF'
          
            mkdir -p /home/cicd/production
          
            # Installer docker compose v2 si n√©cessaire
            if ! docker compose version &> /dev/null; then
              mkdir -p ~/.docker/cli-plugins
              curl -SL https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) \
                -o ~/.docker/cli-plugins/docker-compose
              chmod +x ~/.docker/cli-plugins/docker-compose
            fi
          
            rm -rf /home/cicd/production/*
          EOF

      - name: Envoyer le paquet de d√©ploiement
        run: |
          sshpass -p '${{ secrets.PROD_SSH_PASSWORD }}' scp -o StrictHostKeyChecking=no \
            production-deployment.tar.gz \
            ${{ secrets.PROD_SSH_USER }}@${{ secrets.PROD_SSH_HOST }}:/home/cicd/

      - name: D√©ployer la nouvelle version
        run: |
          sshpass -p '${{ secrets.PROD_SSH_PASSWORD }}' ssh -o StrictHostKeyChecking=no \
            ${{ secrets.PROD_SSH_USER }}@${{ secrets.PROD_SSH_HOST }} << 'EOF'
          
            set -e
          
            cd /home/cicd
            tar -xzf production-deployment.tar.gz -C production/
            cd production
          
            cp .env.production .env
            docker compose down --volumes || true
            docker compose -f compose.yml -f compose.prod.yml up -d --build
          
            echo "‚è≥ Attente du d√©marrage..."
          
            # Attendre que les services soient healthy
            timeout=120
            elapsed=0
            while [ $elapsed -lt $timeout ]; do
              if docker compose ps --filter "status=running" | grep -q "healthy\|Up"; then
                healthy_count=$(docker compose ps --filter "status=running" | grep -c "healthy\|Up" || echo "0")
                if [ "$healthy_count" -ge 3 ]; then
                  echo "‚úÖ Services d√©marr√©s avec succ√®s"
                  break
                fi
              fi
              echo "‚è≥ Attente des services... ($elapsed/$timeout s)"
              sleep 5
              elapsed=$((elapsed + 5))
            done
          
            docker compose ps
          EOF

      - name: V√©rifications sant√© de la prod avec retry
        run: |
          echo "üè• V√©rifications de sant√© production"
          
          # Fonction de retry pour production
          retry_curl_prod() {
            local url=$1
            local service_name=$2
            local max_attempts=10
            local wait_time=10
          
            for i in $(seq 1 $max_attempts); do
              echo "Tentative $i/$max_attempts pour $service_name..."
              if curl -f --connect-timeout 10 --max-time 30 "$url"; then
                echo "‚úÖ $service_name disponible"
                return 0
              fi
              echo "‚è≥ $service_name non disponible, attente ${wait_time}s..."
              sleep $wait_time
            done
          
            echo "‚ùå $service_name indisponible apr√®s $max_attempts tentatives"
            return 1
          }
          
          # Test API
          if ! retry_curl_prod "http://212.83.130.245:4001/health" "API Production"; then
            exit 1
          fi
          
          # Test Frontend
          if ! retry_curl_prod "http://212.83.130.245:4000" "Frontend Production"; then
            exit 1
          fi
          
          # Test temps de r√©ponse
          echo "Test temps de r√©ponse..."
          response_time=$(curl -o /dev/null -s -w "%{time_total}" http://212.83.130.245:4001/health)
          echo "‚è± Temps r√©ponse API : ${response_time}s"
          
          if (( $(echo "$response_time > 2.0" | bc -l) )); then
            echo "‚ö†Ô∏è Temps de r√©ponse √©lev√©"
          fi
          
          echo "‚úÖ D√©ploiement production OK"

      - name: Notifier le succ√®s du d√©ploiement
        run: |
          echo "üéâ Production d√©ploy√©e avec succ√®s !"
          echo "Version: ${{ github.ref_name }}"
          echo "URL: http://212.83.130.245:4000"

  notify_webhook_success:
    if: success()
    needs: [ deploy_staging, deploy_production ]
    runs-on: ubuntu-latest
    steps:
      - name: Notify success
        run: |
          curl -X POST ${{ secrets.WEBHOOK_URL }} \
            -H "Content-Type: application/json" \
            -d '{
              "status": "success", 
              "message": "‚úÖ Build & deploy completed",
              "project": "${{ env.PROJECT_NAME }}",
              "version": "${{ github.ref_name }}",
              "environment": "production"
            }'

  notify_webhook_failure:
    if: failure()
    runs-on: ubuntu-latest
    steps:
      - name: Notify failure
        run: |
          curl -X POST ${{ secrets.WEBHOOK_URL }} \
            -H "Content-Type: application/json" \
            -d '{
              "status": "failure", 
              "message": "‚ùå √âchec du pipeline CI/CD",
              "project": "${{ env.PROJECT_NAME }}",
              "branch": "${{ github.ref_name }}"
            }'